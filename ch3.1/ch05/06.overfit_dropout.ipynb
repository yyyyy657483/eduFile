{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 학습관련기술들   \n",
        "- 드롭아웃을 적용한 신경망으로 학습 및 테스트를 구현하자\n",
        "- 오버피팅(Over-fitting)\n",
        "    + 훈련 데이터에만 너무 적응해 버려서 시험데이터에 제대로 대응하지 못하는 현상\n",
        "    + 매개변수에 비해 상대적으로 훈련 데이터 수가 적을때 발생함\n",
        "- 드롭아웃\n",
        "    + 오버피팅 억제 방법\n",
        "    + 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제하는 방법. 즉, 신호를 전달하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1720147789183
        }
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "print(os.getcwd())\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss:2.308708258254836\n",
            "=== epoch:1, train acc:0.10666666666666667, test acc:0.0885 ===\n",
            "train loss:2.3139177178545007\n",
            "train loss:2.29483126894528\n",
            "train loss:2.282361093789328\n",
            "=== epoch:2, train acc:0.1, test acc:0.0867 ===\n",
            "train loss:2.2954574312645337\n",
            "train loss:2.310422215546757\n",
            "train loss:2.296291938919323\n",
            "=== epoch:3, train acc:0.1, test acc:0.0872 ===\n",
            "train loss:2.297042658674721\n",
            "train loss:2.2970776671538364\n",
            "train loss:2.3048493224651825\n",
            "=== epoch:4, train acc:0.10333333333333333, test acc:0.0872 ===\n",
            "train loss:2.283135509774817\n",
            "train loss:2.2919991997426665\n",
            "train loss:2.294857849626554\n",
            "=== epoch:5, train acc:0.10666666666666667, test acc:0.0888 ===\n",
            "train loss:2.2836055494393537\n",
            "train loss:2.3006994971321078\n",
            "train loss:2.298022423247096\n",
            "=== epoch:6, train acc:0.10666666666666667, test acc:0.0892 ===\n",
            "train loss:2.3087974441555286\n",
            "train loss:2.286338347525473\n",
            "train loss:2.2643561975214355\n",
            "=== epoch:7, train acc:0.10666666666666667, test acc:0.091 ===\n",
            "train loss:2.2954667864329115\n",
            "train loss:2.2712082472421535\n",
            "train loss:2.3106783454239923\n",
            "=== epoch:8, train acc:0.10333333333333333, test acc:0.0925 ===\n",
            "train loss:2.2760614830423678\n",
            "train loss:2.3063365639966227\n",
            "train loss:2.299506494278091\n",
            "=== epoch:9, train acc:0.10333333333333333, test acc:0.0937 ===\n",
            "train loss:2.277580598710026\n",
            "train loss:2.286254678933041\n",
            "train loss:2.286132663540952\n",
            "=== epoch:10, train acc:0.11666666666666667, test acc:0.0956 ===\n",
            "train loss:2.2596690709783864\n",
            "train loss:2.2783350021681636\n",
            "train loss:2.26880330346574\n",
            "=== epoch:11, train acc:0.12, test acc:0.0985 ===\n",
            "train loss:2.293851899111694\n",
            "train loss:2.2999569767902557\n",
            "train loss:2.259021082014382\n",
            "=== epoch:12, train acc:0.12, test acc:0.1005 ===\n",
            "train loss:2.2652876255878085\n",
            "train loss:2.2610862567449237\n",
            "train loss:2.2971599104294915\n",
            "=== epoch:13, train acc:0.12333333333333334, test acc:0.1042 ===\n",
            "train loss:2.2819841762256545\n",
            "train loss:2.2829264767856885\n",
            "train loss:2.2738396698934316\n",
            "=== epoch:14, train acc:0.13333333333333333, test acc:0.1073 ===\n",
            "train loss:2.2545950295792703\n",
            "train loss:2.26459101349263\n",
            "train loss:2.291289129569114\n",
            "=== epoch:15, train acc:0.14, test acc:0.1106 ===\n",
            "train loss:2.2677060108116387\n",
            "train loss:2.2551287482100486\n",
            "train loss:2.3027192977231854\n",
            "=== epoch:16, train acc:0.13666666666666666, test acc:0.1124 ===\n",
            "train loss:2.2871606365403037\n",
            "train loss:2.276332273182524\n",
            "train loss:2.2560637769097895\n",
            "=== epoch:17, train acc:0.13666666666666666, test acc:0.114 ===\n",
            "train loss:2.283501317697573\n",
            "train loss:2.2543110081261744\n",
            "train loss:2.2719306655202764\n",
            "=== epoch:18, train acc:0.13333333333333333, test acc:0.1168 ===\n",
            "train loss:2.289053211476029\n",
            "train loss:2.2608651301308247\n",
            "train loss:2.264306494427086\n",
            "=== epoch:19, train acc:0.13333333333333333, test acc:0.1179 ===\n",
            "train loss:2.2723555235025987\n",
            "train loss:2.2543008310311086\n",
            "train loss:2.2483440427121995\n",
            "=== epoch:20, train acc:0.15333333333333332, test acc:0.1213 ===\n",
            "train loss:2.2913060855744245\n",
            "train loss:2.2425517416133123\n",
            "train loss:2.281995062232549\n",
            "=== epoch:21, train acc:0.17, test acc:0.1241 ===\n",
            "train loss:2.2676970370182556\n",
            "train loss:2.248716324871467\n",
            "train loss:2.2748572102872067\n",
            "=== epoch:22, train acc:0.15666666666666668, test acc:0.1269 ===\n",
            "train loss:2.263781474935507\n",
            "train loss:2.264050613411686\n",
            "train loss:2.24591620035337\n",
            "=== epoch:23, train acc:0.16, test acc:0.1264 ===\n",
            "train loss:2.267454011752503\n",
            "train loss:2.2540112320607846\n",
            "train loss:2.253868389278034\n",
            "=== epoch:24, train acc:0.15333333333333332, test acc:0.1305 ===\n",
            "train loss:2.2641737333166283\n",
            "train loss:2.2463877552060443\n",
            "train loss:2.2490054473243744\n",
            "=== epoch:25, train acc:0.16333333333333333, test acc:0.1329 ===\n",
            "train loss:2.2537542175289538\n",
            "train loss:2.270207797866747\n",
            "train loss:2.260537436165927\n",
            "=== epoch:26, train acc:0.16666666666666666, test acc:0.1357 ===\n",
            "train loss:2.2518089589746695\n",
            "train loss:2.2630972514787486\n",
            "train loss:2.2545207368604356\n",
            "=== epoch:27, train acc:0.16333333333333333, test acc:0.1381 ===\n",
            "train loss:2.2551103983264826\n",
            "train loss:2.2398289438034933\n",
            "train loss:2.251454529904876\n",
            "=== epoch:28, train acc:0.16, test acc:0.1364 ===\n",
            "train loss:2.240580604750768\n",
            "train loss:2.266437034781527\n",
            "train loss:2.2482600304051137\n",
            "=== epoch:29, train acc:0.16666666666666666, test acc:0.1387 ===\n",
            "train loss:2.2757327425376617\n",
            "train loss:2.2528064426993955\n",
            "train loss:2.242658838097631\n",
            "=== epoch:30, train acc:0.16333333333333333, test acc:0.1367 ===\n",
            "train loss:2.2777128485093545\n",
            "train loss:2.23465158333024\n",
            "train loss:2.264766354423996\n",
            "=== epoch:31, train acc:0.17333333333333334, test acc:0.1383 ===\n",
            "train loss:2.2611969589048004\n",
            "train loss:2.2659409758182614\n",
            "train loss:2.240369019813302\n",
            "=== epoch:32, train acc:0.17666666666666667, test acc:0.1434 ===\n",
            "train loss:2.2463486289235153\n",
            "train loss:2.249059416412781\n",
            "train loss:2.2697238898643075\n",
            "=== epoch:33, train acc:0.17666666666666667, test acc:0.1498 ===\n",
            "train loss:2.2608674458991618\n",
            "train loss:2.226303134656527\n",
            "train loss:2.234247394549859\n",
            "=== epoch:34, train acc:0.18666666666666668, test acc:0.1542 ===\n",
            "train loss:2.231023538313932\n",
            "train loss:2.2621420549443765\n",
            "train loss:2.2846705528459186\n",
            "=== epoch:35, train acc:0.19, test acc:0.1561 ===\n",
            "train loss:2.2575727656209903\n",
            "train loss:2.2675773448085375\n",
            "train loss:2.267889506197848\n",
            "=== epoch:36, train acc:0.2, test acc:0.1606 ===\n",
            "train loss:2.233103922730868\n",
            "train loss:2.27264560813517\n",
            "train loss:2.2318068141466982\n",
            "=== epoch:37, train acc:0.18666666666666668, test acc:0.1557 ===\n",
            "train loss:2.2431599046087527\n",
            "train loss:2.2322711757508586\n",
            "train loss:2.2508716576139567\n",
            "=== epoch:38, train acc:0.18666666666666668, test acc:0.1615 ===\n",
            "train loss:2.2424596605350042\n",
            "train loss:2.24438482316941\n",
            "train loss:2.248662506758237\n",
            "=== epoch:39, train acc:0.19, test acc:0.1644 ===\n",
            "train loss:2.2557093138117734\n",
            "train loss:2.253911334782994\n",
            "train loss:2.2464713643968026\n",
            "=== epoch:40, train acc:0.19, test acc:0.1702 ===\n",
            "train loss:2.2503671236725573\n",
            "train loss:2.2249047675923697\n",
            "train loss:2.2415335571359716\n",
            "=== epoch:41, train acc:0.2, test acc:0.1796 ===\n",
            "train loss:2.240000414164866\n",
            "train loss:2.233208370840938\n",
            "train loss:2.250475332836865\n",
            "=== epoch:42, train acc:0.2, test acc:0.1829 ===\n",
            "train loss:2.2612478792833675\n",
            "train loss:2.226340021653696\n",
            "train loss:2.250378373979753\n",
            "=== epoch:43, train acc:0.21, test acc:0.189 ===\n",
            "train loss:2.2386371150342037\n",
            "train loss:2.2136305135346244\n",
            "train loss:2.240341901712462\n",
            "=== epoch:44, train acc:0.21, test acc:0.1866 ===\n",
            "train loss:2.2385488877720774\n",
            "train loss:2.2412825313563003\n",
            "train loss:2.221463774673309\n",
            "=== epoch:45, train acc:0.21, test acc:0.1879 ===\n",
            "train loss:2.259801040797953\n",
            "train loss:2.2222610468971356\n",
            "train loss:2.2456733602108807\n",
            "=== epoch:46, train acc:0.22666666666666666, test acc:0.1996 ===\n",
            "train loss:2.2665328934970237\n",
            "train loss:2.2231789294181423\n",
            "train loss:2.244302236653385\n",
            "=== epoch:47, train acc:0.23666666666666666, test acc:0.2042 ===\n",
            "train loss:2.2182595544087835\n",
            "train loss:2.210492164464132\n",
            "train loss:2.2115924859619285\n",
            "=== epoch:48, train acc:0.23, test acc:0.1983 ===\n",
            "train loss:2.239609968639366\n",
            "train loss:2.228009875157461\n",
            "train loss:2.2101027641685174\n",
            "=== epoch:49, train acc:0.22666666666666666, test acc:0.1966 ===\n",
            "train loss:2.24216551168606\n",
            "train loss:2.2381811821021103\n",
            "train loss:2.2033046535329013\n",
            "=== epoch:50, train acc:0.23, test acc:0.1979 ===\n",
            "train loss:2.208815025930203\n",
            "train loss:2.2160752527176095\n",
            "train loss:2.24433096448706\n",
            "=== epoch:51, train acc:0.22333333333333333, test acc:0.1936 ===\n",
            "train loss:2.224933396406837\n",
            "train loss:2.2017913754651017\n",
            "train loss:2.2378861190294823\n",
            "=== epoch:52, train acc:0.24, test acc:0.1975 ===\n",
            "train loss:2.2043100180820834\n",
            "train loss:2.2291156659047973\n",
            "train loss:2.232176370907167\n",
            "=== epoch:53, train acc:0.24, test acc:0.2025 ===\n",
            "train loss:2.206623052901426\n",
            "train loss:2.196315678041892\n",
            "train loss:2.2299603778602837\n",
            "=== epoch:54, train acc:0.24, test acc:0.1976 ===\n",
            "train loss:2.242818038057723\n",
            "train loss:2.23514847733981\n",
            "train loss:2.220978481044301\n",
            "=== epoch:55, train acc:0.24, test acc:0.2013 ===\n",
            "train loss:2.2106786655390254\n",
            "train loss:2.2187487365911336\n",
            "train loss:2.206787989861245\n",
            "=== epoch:56, train acc:0.24333333333333335, test acc:0.201 ===\n",
            "train loss:2.2082371062970414\n",
            "train loss:2.195432393017463\n",
            "train loss:2.2267199257013934\n",
            "=== epoch:57, train acc:0.26, test acc:0.2179 ===\n",
            "train loss:2.227174980043219\n",
            "train loss:2.1845060755332404\n",
            "train loss:2.209463682395088\n",
            "=== epoch:58, train acc:0.26666666666666666, test acc:0.221 ===\n",
            "train loss:2.176805459917741\n",
            "train loss:2.211410851501901\n",
            "train loss:2.2156802264118416\n",
            "=== epoch:59, train acc:0.2733333333333333, test acc:0.2235 ===\n",
            "train loss:2.2337864330687\n",
            "train loss:2.208571928819967\n",
            "train loss:2.2256749573193604\n",
            "=== epoch:60, train acc:0.26666666666666666, test acc:0.2254 ===\n",
            "train loss:2.213226932557482\n",
            "train loss:2.19723735598281\n",
            "train loss:2.210369956140218\n",
            "=== epoch:61, train acc:0.26666666666666666, test acc:0.2258 ===\n",
            "train loss:2.204006959089384\n",
            "train loss:2.18755276495274\n",
            "train loss:2.195750036725797\n",
            "=== epoch:62, train acc:0.27, test acc:0.2266 ===\n",
            "train loss:2.210495067549095\n",
            "train loss:2.2071063430272453\n",
            "train loss:2.224776600942934\n",
            "=== epoch:63, train acc:0.2833333333333333, test acc:0.2309 ===\n",
            "train loss:2.180450327000996\n",
            "train loss:2.1831219937437676\n",
            "train loss:2.1902223833186265\n",
            "=== epoch:64, train acc:0.2866666666666667, test acc:0.2323 ===\n",
            "train loss:2.1712855607383013\n",
            "train loss:2.197513505254214\n",
            "train loss:2.172814303732836\n",
            "=== epoch:65, train acc:0.2866666666666667, test acc:0.2299 ===\n",
            "train loss:2.213119066035525\n",
            "train loss:2.1796426244667533\n",
            "train loss:2.1877454577204496\n",
            "=== epoch:66, train acc:0.27666666666666667, test acc:0.2268 ===\n",
            "train loss:2.2145596598216866\n",
            "train loss:2.1979559386623664\n",
            "train loss:2.2390083300769588\n",
            "=== epoch:67, train acc:0.28, test acc:0.2282 ===\n",
            "train loss:2.1931982735911313\n",
            "train loss:2.178212649311323\n",
            "train loss:2.187517690016\n",
            "=== epoch:68, train acc:0.2866666666666667, test acc:0.2288 ===\n",
            "train loss:2.207442569973566\n",
            "train loss:2.1866114363036373\n",
            "train loss:2.227292751669404\n",
            "=== epoch:69, train acc:0.2866666666666667, test acc:0.2353 ===\n",
            "train loss:2.1537464425228143\n",
            "train loss:2.205581806944142\n",
            "train loss:2.2127747943191736\n",
            "=== epoch:70, train acc:0.2866666666666667, test acc:0.2358 ===\n",
            "train loss:2.195675000587683\n",
            "train loss:2.168791281525994\n",
            "train loss:2.227210024396446\n",
            "=== epoch:71, train acc:0.27, test acc:0.2322 ===\n",
            "train loss:2.1881822945040987\n",
            "train loss:2.2118172127156104\n",
            "train loss:2.1740970053444766\n",
            "=== epoch:72, train acc:0.2866666666666667, test acc:0.2346 ===\n",
            "train loss:2.193138480448902\n",
            "train loss:2.1796708826929394\n",
            "train loss:2.19741301560032\n",
            "=== epoch:73, train acc:0.2866666666666667, test acc:0.2349 ===\n",
            "train loss:2.1601575233132597\n",
            "train loss:2.1482960196255925\n",
            "train loss:2.148001282811077\n",
            "=== epoch:74, train acc:0.27666666666666667, test acc:0.2286 ===\n",
            "train loss:2.1694057308765333\n",
            "train loss:2.143315219752751\n",
            "train loss:2.186720362075679\n",
            "=== epoch:75, train acc:0.2733333333333333, test acc:0.2265 ===\n",
            "train loss:2.1823201134540158\n",
            "train loss:2.181280259152646\n",
            "train loss:2.2092910679798687\n",
            "=== epoch:76, train acc:0.2833333333333333, test acc:0.2297 ===\n",
            "train loss:2.1641981189786064\n",
            "train loss:2.1847528039051025\n",
            "train loss:2.1856199546503015\n",
            "=== epoch:77, train acc:0.29, test acc:0.2337 ===\n",
            "train loss:2.164794413778777\n",
            "train loss:2.1584314970684173\n",
            "train loss:2.180676481288955\n",
            "=== epoch:78, train acc:0.29, test acc:0.2357 ===\n",
            "train loss:2.1742539669422456\n",
            "train loss:2.1453365410192653\n",
            "train loss:2.1473747267391907\n",
            "=== epoch:79, train acc:0.29333333333333333, test acc:0.2358 ===\n",
            "train loss:2.1536619512046773\n",
            "train loss:2.158190228152617\n",
            "train loss:2.176808568507568\n",
            "=== epoch:80, train acc:0.29, test acc:0.2382 ===\n",
            "train loss:2.1533042873192696\n",
            "train loss:2.129663943990627\n",
            "train loss:2.0978371572624566\n",
            "=== epoch:81, train acc:0.27666666666666667, test acc:0.2329 ===\n",
            "train loss:2.1741977887918438\n",
            "train loss:2.154948529214862\n",
            "train loss:2.210294367469462\n",
            "=== epoch:82, train acc:0.2833333333333333, test acc:0.2364 ===\n",
            "train loss:2.1861269951527076\n",
            "train loss:2.1328439577020397\n",
            "train loss:2.1526682731607\n",
            "=== epoch:83, train acc:0.28, test acc:0.2373 ===\n",
            "train loss:2.163484764221075\n",
            "train loss:2.177631920070453\n",
            "train loss:2.1705126708719225\n",
            "=== epoch:84, train acc:0.30333333333333334, test acc:0.2436 ===\n",
            "train loss:2.156687196100971\n",
            "train loss:2.10374102123124\n",
            "train loss:2.1440611756653043\n",
            "=== epoch:85, train acc:0.3, test acc:0.2436 ===\n",
            "train loss:2.1034133727036988\n",
            "train loss:2.1064579027631063\n",
            "train loss:2.1672619853005815\n",
            "=== epoch:86, train acc:0.29, test acc:0.2408 ===\n",
            "train loss:2.1289309965005945\n",
            "train loss:2.1810134176314726\n",
            "train loss:2.1599119858996776\n",
            "=== epoch:87, train acc:0.30333333333333334, test acc:0.248 ===\n",
            "train loss:2.142514951448091\n",
            "train loss:2.093659707310107\n",
            "train loss:2.1658930549862534\n",
            "=== epoch:88, train acc:0.30666666666666664, test acc:0.2485 ===\n",
            "train loss:2.1726836073165563\n",
            "train loss:2.185575103287564\n",
            "train loss:2.1438740416877162\n",
            "=== epoch:89, train acc:0.31333333333333335, test acc:0.2517 ===\n",
            "train loss:2.1535044946571205\n",
            "train loss:2.1771663149338187\n",
            "train loss:2.084356611765143\n",
            "=== epoch:90, train acc:0.30666666666666664, test acc:0.2526 ===\n",
            "train loss:2.1281790587256686\n",
            "train loss:2.10840131489532\n",
            "train loss:2.1167138648662167\n",
            "=== epoch:91, train acc:0.31, test acc:0.2526 ===\n",
            "train loss:2.096358184435044\n",
            "train loss:2.1649659969584074\n",
            "train loss:2.0996872694328506\n",
            "=== epoch:92, train acc:0.3, test acc:0.251 ===\n",
            "train loss:2.125164373689087\n",
            "train loss:2.1185950546416303\n",
            "train loss:2.1531872234630125\n",
            "=== epoch:93, train acc:0.30666666666666664, test acc:0.2553 ===\n",
            "train loss:2.092320046736857\n",
            "train loss:2.1846050212437915\n",
            "train loss:2.1305987488771714\n",
            "=== epoch:94, train acc:0.31333333333333335, test acc:0.2574 ===\n",
            "train loss:2.112633823352854\n",
            "train loss:2.1615904500638266\n",
            "train loss:2.137031861077081\n",
            "=== epoch:95, train acc:0.31333333333333335, test acc:0.2619 ===\n",
            "train loss:2.079020953525578\n",
            "train loss:2.1052111366175\n",
            "train loss:2.1318969815171243\n",
            "=== epoch:96, train acc:0.31, test acc:0.2618 ===\n",
            "train loss:2.0931820934652796\n",
            "train loss:2.098418525340045\n",
            "train loss:2.1048707261975106\n",
            "=== epoch:97, train acc:0.31666666666666665, test acc:0.2645 ===\n",
            "train loss:2.0700692988107163\n",
            "train loss:2.118642914519407\n",
            "train loss:2.066239940651623\n",
            "=== epoch:98, train acc:0.31666666666666665, test acc:0.2652 ===\n",
            "train loss:2.116616265616903\n",
            "train loss:2.0828494128022923\n",
            "train loss:2.1372412086882178\n",
            "=== epoch:99, train acc:0.32666666666666666, test acc:0.2686 ===\n",
            "train loss:2.075400852691928\n",
            "train loss:2.140130433401635\n",
            "train loss:2.149070778843777\n",
            "=== epoch:100, train acc:0.33, test acc:0.2729 ===\n",
            "train loss:2.1693597582924617\n",
            "train loss:2.036990109691802\n",
            "train loss:2.1074113533860235\n",
            "=== epoch:101, train acc:0.33, test acc:0.272 ===\n",
            "train loss:2.0760272852325325\n",
            "train loss:2.1138515384904655\n",
            "train loss:2.1327017808151507\n",
            "=== epoch:102, train acc:0.33, test acc:0.2753 ===\n",
            "train loss:2.147548906791981\n",
            "train loss:2.079299270905827\n",
            "train loss:2.0918790418545665\n",
            "=== epoch:103, train acc:0.33666666666666667, test acc:0.2763 ===\n",
            "train loss:2.0894564972919976\n",
            "train loss:2.1193830182523437\n",
            "train loss:2.062013530130364\n",
            "=== epoch:104, train acc:0.3333333333333333, test acc:0.2784 ===\n",
            "train loss:2.0760491176190645\n",
            "train loss:2.0858460191583883\n",
            "train loss:2.073019581003849\n",
            "=== epoch:105, train acc:0.33666666666666667, test acc:0.2804 ===\n",
            "train loss:2.07807201596632\n",
            "train loss:2.0712842640773603\n",
            "train loss:2.018863152439354\n",
            "=== epoch:106, train acc:0.3333333333333333, test acc:0.2786 ===\n",
            "train loss:2.1157665514864896\n",
            "train loss:2.088789013991306\n",
            "train loss:2.0710042049159982\n",
            "=== epoch:107, train acc:0.3433333333333333, test acc:0.2821 ===\n",
            "train loss:2.050453460459341\n",
            "train loss:2.0327656386842405\n",
            "train loss:2.073487334262774\n",
            "=== epoch:108, train acc:0.3466666666666667, test acc:0.2814 ===\n",
            "train loss:2.044131473539291\n",
            "train loss:2.0366947138730342\n",
            "train loss:2.1068002705949866\n",
            "=== epoch:109, train acc:0.3566666666666667, test acc:0.2842 ===\n",
            "train loss:2.042740346323245\n",
            "train loss:2.054203239352204\n",
            "train loss:2.095979015888575\n",
            "=== epoch:110, train acc:0.36333333333333334, test acc:0.2897 ===\n",
            "train loss:2.0600602582834053\n",
            "train loss:2.0896314261120446\n",
            "train loss:1.9828762296926357\n",
            "=== epoch:111, train acc:0.36333333333333334, test acc:0.2902 ===\n",
            "train loss:2.0379132207093167\n",
            "train loss:2.049354046935045\n",
            "train loss:2.0423610158350254\n",
            "=== epoch:112, train acc:0.36, test acc:0.2884 ===\n",
            "train loss:2.0798595311186396\n",
            "train loss:2.0742655040222058\n",
            "train loss:2.1065177687199768\n",
            "=== epoch:113, train acc:0.36, test acc:0.2918 ===\n",
            "train loss:1.9556424843741507\n",
            "train loss:2.140793861013674\n",
            "train loss:2.0840687032151464\n",
            "=== epoch:114, train acc:0.3566666666666667, test acc:0.2925 ===\n",
            "train loss:2.0659493214811047\n",
            "train loss:2.092831848281177\n",
            "train loss:2.017451884713785\n",
            "=== epoch:115, train acc:0.37333333333333335, test acc:0.299 ===\n",
            "train loss:2.0294471434633\n",
            "train loss:2.0621646047071662\n",
            "train loss:2.044941841422501\n",
            "=== epoch:116, train acc:0.37666666666666665, test acc:0.301 ===\n",
            "train loss:2.0637436858917733\n",
            "train loss:2.108579577093541\n",
            "train loss:2.0486110066019\n",
            "=== epoch:117, train acc:0.38333333333333336, test acc:0.3055 ===\n",
            "train loss:2.108421013053329\n",
            "train loss:2.085342272632741\n",
            "train loss:2.050119869965646\n",
            "=== epoch:118, train acc:0.38666666666666666, test acc:0.3136 ===\n",
            "train loss:1.9911962128019514\n",
            "train loss:2.0242965227484713\n",
            "train loss:2.044380002656186\n",
            "=== epoch:119, train acc:0.3933333333333333, test acc:0.3166 ===\n",
            "train loss:2.132415025245617\n",
            "train loss:2.008170160187212\n",
            "train loss:1.9546385189396842\n",
            "=== epoch:120, train acc:0.39, test acc:0.3201 ===\n",
            "train loss:2.0626058169416144\n",
            "train loss:2.022528563789111\n",
            "train loss:2.082778346176482\n",
            "=== epoch:121, train acc:0.39666666666666667, test acc:0.3188 ===\n",
            "train loss:2.0384916080340183\n",
            "train loss:2.002145902549886\n",
            "train loss:2.046569273259029\n",
            "=== epoch:122, train acc:0.39666666666666667, test acc:0.3213 ===\n",
            "train loss:2.078701458174681\n",
            "train loss:2.027791720633568\n",
            "train loss:2.0453154503805795\n",
            "=== epoch:123, train acc:0.4, test acc:0.3259 ===\n",
            "train loss:2.07021205786573\n",
            "train loss:1.9811999703944627\n",
            "train loss:2.072380278600673\n",
            "=== epoch:124, train acc:0.39666666666666667, test acc:0.3204 ===\n",
            "train loss:2.0058111399290612\n",
            "train loss:2.0102262521765306\n",
            "train loss:2.0361354419852655\n",
            "=== epoch:125, train acc:0.4033333333333333, test acc:0.321 ===\n",
            "train loss:2.0004995707282003\n",
            "train loss:2.017420375379647\n",
            "train loss:1.9651291702423688\n",
            "=== epoch:126, train acc:0.38666666666666666, test acc:0.3152 ===\n",
            "train loss:2.0131316870872626\n",
            "train loss:1.9699643476181095\n",
            "train loss:2.0543951205703292\n",
            "=== epoch:127, train acc:0.38666666666666666, test acc:0.3181 ===\n",
            "train loss:2.021778706369763\n",
            "train loss:2.090769144265285\n",
            "train loss:1.9709140008599317\n",
            "=== epoch:128, train acc:0.4066666666666667, test acc:0.3244 ===\n",
            "train loss:1.9698292777987723\n",
            "train loss:1.9671038187268715\n",
            "train loss:2.0687906549531268\n",
            "=== epoch:129, train acc:0.41, test acc:0.3278 ===\n",
            "train loss:1.9813770236747432\n",
            "train loss:1.9581560480356044\n",
            "train loss:2.00207094248548\n",
            "=== epoch:130, train acc:0.4066666666666667, test acc:0.3298 ===\n",
            "train loss:2.0223095441779346\n",
            "train loss:1.9740416569407333\n",
            "train loss:1.9593906877192169\n",
            "=== epoch:131, train acc:0.41, test acc:0.3306 ===\n",
            "train loss:1.9543407603471\n",
            "train loss:2.043764459271716\n",
            "train loss:1.9618794535545956\n",
            "=== epoch:132, train acc:0.4166666666666667, test acc:0.3363 ===\n",
            "train loss:1.9542059805347065\n",
            "train loss:2.001658008857791\n",
            "train loss:1.9730141978291797\n",
            "=== epoch:133, train acc:0.42, test acc:0.3418 ===\n",
            "train loss:1.9845149913257005\n",
            "train loss:2.0092250255088615\n",
            "train loss:2.0746892630991765\n",
            "=== epoch:134, train acc:0.43, test acc:0.3446 ===\n",
            "train loss:1.95402329034123\n",
            "train loss:2.017936809851073\n",
            "train loss:2.0362162201723706\n",
            "=== epoch:135, train acc:0.44, test acc:0.3464 ===\n",
            "train loss:1.929742658844949\n",
            "train loss:1.975736336511398\n",
            "train loss:1.9632573845183259\n",
            "=== epoch:136, train acc:0.44333333333333336, test acc:0.3482 ===\n",
            "train loss:1.9772560416051792\n",
            "train loss:1.9546140936746264\n",
            "train loss:1.9665349745916345\n",
            "=== epoch:137, train acc:0.44333333333333336, test acc:0.3495 ===\n",
            "train loss:1.9757585980799848\n",
            "train loss:1.9425127062348055\n",
            "train loss:1.8940130432163655\n",
            "=== epoch:138, train acc:0.45666666666666667, test acc:0.3548 ===\n",
            "train loss:1.887841689388598\n",
            "train loss:1.9312555504809583\n",
            "train loss:2.0089482122013145\n",
            "=== epoch:139, train acc:0.4633333333333333, test acc:0.3625 ===\n",
            "train loss:1.9494379045811099\n",
            "train loss:1.9537234138531738\n",
            "train loss:1.9710548728170938\n",
            "=== epoch:140, train acc:0.46, test acc:0.3667 ===\n",
            "train loss:1.9761104666650773\n",
            "train loss:1.953078441318401\n",
            "train loss:1.8336636969689453\n",
            "=== epoch:141, train acc:0.46, test acc:0.3666 ===\n",
            "train loss:1.9619179461393452\n",
            "train loss:1.972023214981662\n",
            "train loss:1.9892242334873067\n",
            "=== epoch:142, train acc:0.4633333333333333, test acc:0.37 ===\n",
            "train loss:1.898630579455054\n",
            "train loss:1.9535628138322594\n",
            "train loss:1.933478284759813\n",
            "=== epoch:143, train acc:0.47333333333333333, test acc:0.3747 ===\n",
            "train loss:1.9822472103286213\n",
            "train loss:1.9992969976495394\n",
            "train loss:1.9790795018481164\n",
            "=== epoch:144, train acc:0.47, test acc:0.3776 ===\n",
            "train loss:1.8421161957445154\n",
            "train loss:1.9493417834931086\n",
            "train loss:1.9678287150610252\n",
            "=== epoch:145, train acc:0.4666666666666667, test acc:0.375 ===\n",
            "train loss:1.9061351478106565\n",
            "train loss:1.9528742492456328\n",
            "train loss:1.9369286403664914\n",
            "=== epoch:146, train acc:0.47, test acc:0.3769 ===\n",
            "train loss:2.001516372185624\n",
            "train loss:1.952047161191336\n",
            "train loss:1.910305263055487\n",
            "=== epoch:147, train acc:0.47, test acc:0.3777 ===\n",
            "train loss:1.9735890760645645\n",
            "train loss:1.9232465035415311\n",
            "train loss:1.9068672289637478\n",
            "=== epoch:148, train acc:0.4666666666666667, test acc:0.3776 ===\n",
            "train loss:1.81900204811892\n",
            "train loss:1.9042374918055256\n",
            "train loss:1.8327732411126374\n",
            "=== epoch:149, train acc:0.46, test acc:0.3742 ===\n",
            "train loss:1.9069632178527456\n",
            "train loss:1.994505529107265\n",
            "train loss:1.99711581125911\n",
            "=== epoch:150, train acc:0.47333333333333333, test acc:0.3831 ===\n",
            "train loss:1.9628781189654316\n",
            "train loss:1.854865233654702\n",
            "train loss:1.830423253563263\n",
            "=== epoch:151, train acc:0.4666666666666667, test acc:0.3804 ===\n",
            "train loss:1.9512000221640866\n",
            "train loss:1.8283342902970154\n",
            "train loss:1.8145634445641718\n",
            "=== epoch:152, train acc:0.4633333333333333, test acc:0.3776 ===\n",
            "train loss:1.937640313643512\n",
            "train loss:1.8980359716554858\n",
            "train loss:1.938669834816879\n",
            "=== epoch:153, train acc:0.47, test acc:0.379 ===\n",
            "train loss:1.8258859056478758\n",
            "train loss:1.7729101224637305\n",
            "train loss:1.9185965695468443\n",
            "=== epoch:154, train acc:0.47333333333333333, test acc:0.3797 ===\n",
            "train loss:1.8771824014468494\n",
            "train loss:1.9909438949609108\n",
            "train loss:1.8972459531050245\n",
            "=== epoch:155, train acc:0.4766666666666667, test acc:0.3868 ===\n",
            "train loss:1.8849561985008423\n",
            "train loss:1.8103391596688467\n",
            "train loss:1.900660886725427\n",
            "=== epoch:156, train acc:0.4766666666666667, test acc:0.3865 ===\n",
            "train loss:1.7102598971829022\n",
            "train loss:1.9668650274706283\n",
            "train loss:1.8130322947806494\n",
            "=== epoch:157, train acc:0.48, test acc:0.3866 ===\n",
            "train loss:1.9562508651747532\n",
            "train loss:1.8733475259224588\n",
            "train loss:1.8431783968917759\n",
            "=== epoch:158, train acc:0.4766666666666667, test acc:0.3876 ===\n",
            "train loss:1.8738416100175102\n",
            "train loss:1.891061060850156\n",
            "train loss:1.8934207405790033\n",
            "=== epoch:159, train acc:0.48, test acc:0.3882 ===\n",
            "train loss:1.8830296234711879\n",
            "train loss:1.888750782266519\n",
            "train loss:1.9154915445259177\n",
            "=== epoch:160, train acc:0.47333333333333333, test acc:0.3872 ===\n",
            "train loss:1.846439668765631\n",
            "train loss:1.8787968025188255\n",
            "train loss:1.9000750624083202\n",
            "=== epoch:161, train acc:0.4766666666666667, test acc:0.3885 ===\n",
            "train loss:1.7840951312594495\n",
            "train loss:1.8936360498614757\n",
            "train loss:1.8815876488061825\n",
            "=== epoch:162, train acc:0.4766666666666667, test acc:0.3884 ===\n",
            "train loss:1.8290260369290174\n",
            "train loss:1.8128256144835464\n",
            "train loss:1.8989897288062298\n",
            "=== epoch:163, train acc:0.48333333333333334, test acc:0.3957 ===\n",
            "train loss:1.8995966193618208\n",
            "train loss:1.8308149222700683\n",
            "train loss:1.8919635917115099\n",
            "=== epoch:164, train acc:0.48333333333333334, test acc:0.3947 ===\n",
            "train loss:1.833828974726042\n",
            "train loss:1.8027685291134614\n",
            "train loss:1.9443781439533745\n",
            "=== epoch:165, train acc:0.48333333333333334, test acc:0.3974 ===\n",
            "train loss:1.8034402401192164\n",
            "train loss:1.7904447447301481\n",
            "train loss:1.7982902710459836\n",
            "=== epoch:166, train acc:0.48333333333333334, test acc:0.3959 ===\n",
            "train loss:1.8152906489165184\n",
            "train loss:1.9210008762670696\n",
            "train loss:1.816146543614721\n",
            "=== epoch:167, train acc:0.48333333333333334, test acc:0.3935 ===\n",
            "train loss:1.7642967938038305\n",
            "train loss:1.8920546180395867\n",
            "train loss:1.7280544281767194\n",
            "=== epoch:168, train acc:0.48, test acc:0.3914 ===\n",
            "train loss:1.810910108270314\n",
            "train loss:1.810448752610453\n",
            "train loss:1.7993352563605751\n",
            "=== epoch:169, train acc:0.48333333333333334, test acc:0.3929 ===\n",
            "train loss:1.7598315649993757\n",
            "train loss:1.956210691322915\n",
            "train loss:1.8257095589688488\n",
            "=== epoch:170, train acc:0.48333333333333334, test acc:0.3954 ===\n",
            "train loss:1.8161609740466362\n",
            "train loss:1.9267916480406517\n",
            "train loss:1.7941967749667709\n",
            "=== epoch:171, train acc:0.49, test acc:0.3984 ===\n",
            "train loss:1.760594939138816\n",
            "train loss:1.87139618524919\n",
            "train loss:1.8259348626554408\n",
            "=== epoch:172, train acc:0.49333333333333335, test acc:0.4 ===\n",
            "train loss:1.8722022484342296\n",
            "train loss:1.835107547083902\n",
            "train loss:1.8260158302863707\n",
            "=== epoch:173, train acc:0.49666666666666665, test acc:0.4024 ===\n",
            "train loss:1.7733034185718584\n",
            "train loss:1.6965085881058564\n",
            "train loss:1.83843910900087\n",
            "=== epoch:174, train acc:0.5, test acc:0.4015 ===\n",
            "train loss:1.9499814612123416\n",
            "train loss:1.786055223719805\n",
            "train loss:1.8017348601198404\n",
            "=== epoch:175, train acc:0.49666666666666665, test acc:0.4012 ===\n",
            "train loss:1.862473076467506\n",
            "train loss:1.8098040733100822\n",
            "train loss:1.7310549181951334\n",
            "=== epoch:176, train acc:0.49333333333333335, test acc:0.4007 ===\n",
            "train loss:1.6997918772464036\n",
            "train loss:1.77295144298722\n",
            "train loss:1.7445526288005846\n",
            "=== epoch:177, train acc:0.49666666666666665, test acc:0.4026 ===\n",
            "train loss:1.8678435838731156\n",
            "train loss:1.7591631252998872\n",
            "train loss:1.7826301235811994\n",
            "=== epoch:178, train acc:0.5, test acc:0.407 ===\n",
            "train loss:1.768259192513813\n",
            "train loss:1.7450525881789705\n",
            "train loss:1.758025810895144\n",
            "=== epoch:179, train acc:0.5066666666666667, test acc:0.4092 ===\n",
            "train loss:1.626501661704681\n",
            "train loss:1.757508313173876\n",
            "train loss:1.6694463541191942\n",
            "=== epoch:180, train acc:0.5033333333333333, test acc:0.4097 ===\n",
            "train loss:1.6952471143584265\n",
            "train loss:1.7448060730213084\n",
            "train loss:1.8773855881831496\n",
            "=== epoch:181, train acc:0.5033333333333333, test acc:0.4103 ===\n",
            "train loss:1.7267573373621845\n",
            "train loss:1.763103117719776\n",
            "train loss:1.8140521727444476\n",
            "=== epoch:182, train acc:0.5033333333333333, test acc:0.41 ===\n",
            "train loss:1.790544749202601\n",
            "train loss:1.708326004111676\n",
            "train loss:1.797413105610486\n",
            "=== epoch:183, train acc:0.5033333333333333, test acc:0.4082 ===\n",
            "train loss:1.8133243438713182\n",
            "train loss:1.7049166286823874\n",
            "train loss:1.7578042651876193\n",
            "=== epoch:184, train acc:0.51, test acc:0.4072 ===\n",
            "train loss:1.7281436397572407\n",
            "train loss:1.7595256914212152\n",
            "train loss:1.913077916112202\n",
            "=== epoch:185, train acc:0.5133333333333333, test acc:0.406 ===\n",
            "train loss:1.7088015489531483\n",
            "train loss:1.7939160839595372\n",
            "train loss:1.8216703332434196\n",
            "=== epoch:186, train acc:0.5133333333333333, test acc:0.4065 ===\n",
            "train loss:1.7643103939265306\n",
            "train loss:1.7960323878041813\n",
            "train loss:1.7510967038219691\n",
            "=== epoch:187, train acc:0.5133333333333333, test acc:0.4055 ===\n",
            "train loss:1.7590658775540187\n",
            "train loss:1.6463371416527464\n",
            "train loss:1.8530869238182899\n",
            "=== epoch:188, train acc:0.5133333333333333, test acc:0.4113 ===\n",
            "train loss:1.6328899683566949\n",
            "train loss:1.6551971323030017\n",
            "train loss:1.7540716626749517\n",
            "=== epoch:189, train acc:0.5133333333333333, test acc:0.4088 ===\n",
            "train loss:1.6044548126048404\n",
            "train loss:1.721760083833392\n",
            "train loss:1.773863072781148\n",
            "=== epoch:190, train acc:0.51, test acc:0.4131 ===\n",
            "train loss:1.8747544960890874\n",
            "train loss:1.730730586764282\n",
            "train loss:1.7599969781621527\n",
            "=== epoch:191, train acc:0.5133333333333333, test acc:0.4133 ===\n",
            "train loss:1.7521123581747222\n",
            "train loss:1.7379023168063548\n",
            "train loss:1.5768767207693444\n",
            "=== epoch:192, train acc:0.5133333333333333, test acc:0.4104 ===\n",
            "train loss:1.734758252007648\n",
            "train loss:1.7421199380995793\n",
            "train loss:1.6596463655973834\n",
            "=== epoch:193, train acc:0.5133333333333333, test acc:0.41 ===\n",
            "train loss:1.640333576117976\n",
            "train loss:1.6667241770950936\n",
            "train loss:1.7619161896557538\n",
            "=== epoch:194, train acc:0.5166666666666667, test acc:0.4079 ===\n",
            "train loss:1.6674676959055648\n",
            "train loss:1.6497966141921345\n",
            "train loss:1.5806172266718697\n",
            "=== epoch:195, train acc:0.51, test acc:0.4082 ===\n",
            "train loss:1.720882623880638\n",
            "train loss:1.6213587663265079\n",
            "train loss:1.675757693287335\n",
            "=== epoch:196, train acc:0.5133333333333333, test acc:0.4109 ===\n",
            "train loss:1.6082542082266635\n",
            "train loss:1.7521864055073328\n",
            "train loss:1.5998226134808706\n",
            "=== epoch:197, train acc:0.5066666666666667, test acc:0.4095 ===\n",
            "train loss:1.7551470004804415\n",
            "train loss:1.759246087735561\n",
            "train loss:1.6298710025554728\n",
            "=== epoch:198, train acc:0.5133333333333333, test acc:0.4099 ===\n",
            "train loss:1.7653879254736033\n",
            "train loss:1.7466759353247199\n",
            "train loss:1.599519616265963\n",
            "=== epoch:199, train acc:0.5133333333333333, test acc:0.4111 ===\n",
            "train loss:1.7180619879836099\n",
            "train loss:1.7173794559574418\n",
            "train loss:1.6517749520138394\n",
            "=== epoch:200, train acc:0.5133333333333333, test acc:0.4123 ===\n",
            "train loss:1.6257628339657413\n",
            "train loss:1.645179276809294\n",
            "train loss:1.5554617839378562\n",
            "=== epoch:201, train acc:0.5166666666666667, test acc:0.4122 ===\n",
            "train loss:1.7642398074066343\n",
            "train loss:1.7338291631712748\n",
            "train loss:1.6112575944442051\n",
            "=== epoch:202, train acc:0.5166666666666667, test acc:0.4128 ===\n",
            "train loss:1.5887138315752054\n",
            "train loss:1.575319084816179\n",
            "train loss:1.6673392161030092\n",
            "=== epoch:203, train acc:0.51, test acc:0.412 ===\n",
            "train loss:1.542344104387787\n",
            "train loss:1.6932112362340686\n",
            "train loss:1.6157227052050644\n",
            "=== epoch:204, train acc:0.5166666666666667, test acc:0.4148 ===\n",
            "train loss:1.6688595687840821\n",
            "train loss:1.5813149154742365\n",
            "train loss:1.6820720726860583\n",
            "=== epoch:205, train acc:0.5133333333333333, test acc:0.4129 ===\n",
            "train loss:1.7102057872578222\n",
            "train loss:1.6263364527813875\n",
            "train loss:1.5170774628583692\n",
            "=== epoch:206, train acc:0.51, test acc:0.4128 ===\n",
            "train loss:1.6330796510730363\n",
            "train loss:1.6716556406590073\n",
            "train loss:1.6928424815729537\n",
            "=== epoch:207, train acc:0.5233333333333333, test acc:0.4136 ===\n",
            "train loss:1.5646323925158385\n",
            "train loss:1.6998732697366261\n",
            "train loss:1.7404491852597943\n",
            "=== epoch:208, train acc:0.52, test acc:0.4154 ===\n",
            "train loss:1.5800438181467462\n",
            "train loss:1.6718884157642275\n",
            "train loss:1.5779718373556246\n",
            "=== epoch:209, train acc:0.51, test acc:0.4151 ===\n",
            "train loss:1.791460940320304\n",
            "train loss:1.7121244044351442\n",
            "train loss:1.608704161330325\n",
            "=== epoch:210, train acc:0.5133333333333333, test acc:0.4164 ===\n",
            "train loss:1.5561707138771212\n",
            "train loss:1.7040574304709986\n",
            "train loss:1.517687416806797\n",
            "=== epoch:211, train acc:0.5066666666666667, test acc:0.4171 ===\n",
            "train loss:1.7347875020918067\n",
            "train loss:1.6343237542112306\n",
            "train loss:1.5838936761406017\n",
            "=== epoch:212, train acc:0.5166666666666667, test acc:0.4185 ===\n",
            "train loss:1.6958893681896612\n",
            "train loss:1.654445380212208\n",
            "train loss:1.4998413272418996\n",
            "=== epoch:213, train acc:0.5233333333333333, test acc:0.4192 ===\n",
            "train loss:1.5848508168300546\n",
            "train loss:1.6258019427463908\n",
            "train loss:1.4420599847689184\n",
            "=== epoch:214, train acc:0.52, test acc:0.4188 ===\n",
            "train loss:1.5843002847786471\n",
            "train loss:1.601703001246854\n",
            "train loss:1.601141143942115\n",
            "=== epoch:215, train acc:0.52, test acc:0.4206 ===\n",
            "train loss:1.4970507683561523\n",
            "train loss:1.5675778490872674\n",
            "train loss:1.7351053705320325\n",
            "=== epoch:216, train acc:0.5166666666666667, test acc:0.422 ===\n",
            "train loss:1.6373172038159893\n",
            "train loss:1.51356158478939\n",
            "train loss:1.6926999090453347\n",
            "=== epoch:217, train acc:0.52, test acc:0.4238 ===\n",
            "train loss:1.6579823725038023\n",
            "train loss:1.590379087297718\n",
            "train loss:1.498599613925365\n",
            "=== epoch:218, train acc:0.52, test acc:0.4228 ===\n",
            "train loss:1.5518203108021544\n",
            "train loss:1.6447577837769631\n",
            "train loss:1.5630816188166219\n",
            "=== epoch:219, train acc:0.5233333333333333, test acc:0.4211 ===\n",
            "train loss:1.6129696878031294\n",
            "train loss:1.570197983197357\n",
            "train loss:1.5896819438052996\n",
            "=== epoch:220, train acc:0.52, test acc:0.4241 ===\n",
            "train loss:1.4068753358154122\n",
            "train loss:1.508026216278088\n",
            "train loss:1.6387862727788476\n",
            "=== epoch:221, train acc:0.52, test acc:0.4264 ===\n",
            "train loss:1.5638305233110013\n",
            "train loss:1.4990181048674984\n",
            "train loss:1.5779362375127106\n",
            "=== epoch:222, train acc:0.5266666666666666, test acc:0.4258 ===\n",
            "train loss:1.5442733313085804\n",
            "train loss:1.518537871148976\n",
            "train loss:1.5730575043035364\n",
            "=== epoch:223, train acc:0.5266666666666666, test acc:0.4262 ===\n",
            "train loss:1.5373952463861136\n",
            "train loss:1.5036946305486802\n",
            "train loss:1.5518906635649363\n",
            "=== epoch:224, train acc:0.5233333333333333, test acc:0.4236 ===\n",
            "train loss:1.4447886097278977\n",
            "train loss:1.634287573122573\n",
            "train loss:1.5336085862148598\n",
            "=== epoch:225, train acc:0.5266666666666666, test acc:0.4272 ===\n",
            "train loss:1.4277812048495537\n",
            "train loss:1.686251698379904\n",
            "train loss:1.4796192648996578\n",
            "=== epoch:226, train acc:0.5266666666666666, test acc:0.4283 ===\n",
            "train loss:1.6263396650038606\n",
            "train loss:1.5366351314737967\n",
            "train loss:1.4520261018522769\n",
            "=== epoch:227, train acc:0.52, test acc:0.4225 ===\n",
            "train loss:1.6044981978613904\n",
            "train loss:1.4556852538992768\n",
            "train loss:1.488914867301918\n",
            "=== epoch:228, train acc:0.52, test acc:0.4241 ===\n",
            "train loss:1.5438938681310206\n",
            "train loss:1.650202710072833\n",
            "train loss:1.5022242695530108\n",
            "=== epoch:229, train acc:0.5266666666666666, test acc:0.4236 ===\n",
            "train loss:1.448128624392723\n",
            "train loss:1.551515645309153\n",
            "train loss:1.424226133019907\n",
            "=== epoch:230, train acc:0.5233333333333333, test acc:0.4254 ===\n",
            "train loss:1.4870599285446102\n",
            "train loss:1.5849042147129928\n",
            "train loss:1.4681966176099035\n",
            "=== epoch:231, train acc:0.5266666666666666, test acc:0.4266 ===\n",
            "train loss:1.6278889790260098\n",
            "train loss:1.5930676060979585\n",
            "train loss:1.4816758722750807\n",
            "=== epoch:232, train acc:0.52, test acc:0.4278 ===\n",
            "train loss:1.6094547064385532\n",
            "train loss:1.4745568849223665\n",
            "train loss:1.5936553332770933\n",
            "=== epoch:233, train acc:0.5166666666666667, test acc:0.4302 ===\n",
            "train loss:1.6086694093982503\n",
            "train loss:1.5168154452694445\n",
            "train loss:1.5250698704632197\n",
            "=== epoch:234, train acc:0.52, test acc:0.4314 ===\n",
            "train loss:1.4369173450496466\n",
            "train loss:1.2277675655121525\n",
            "train loss:1.393800294007561\n",
            "=== epoch:235, train acc:0.5166666666666667, test acc:0.4303 ===\n",
            "train loss:1.4456486375842992\n",
            "train loss:1.5053070081073108\n",
            "train loss:1.5351043425528794\n",
            "=== epoch:236, train acc:0.5166666666666667, test acc:0.4319 ===\n",
            "train loss:1.5728971857474525\n",
            "train loss:1.5076502288405909\n",
            "train loss:1.6254548928683994\n",
            "=== epoch:237, train acc:0.5233333333333333, test acc:0.4352 ===\n",
            "train loss:1.416697142495864\n",
            "train loss:1.6011000711768466\n",
            "train loss:1.5412687839597137\n",
            "=== epoch:238, train acc:0.52, test acc:0.4348 ===\n",
            "train loss:1.522967967049688\n",
            "train loss:1.3839032906574942\n",
            "train loss:1.621520092708285\n",
            "=== epoch:239, train acc:0.52, test acc:0.4331 ===\n",
            "train loss:1.4980121928393912\n",
            "train loss:1.5153924272441244\n",
            "train loss:1.6372791611958801\n",
            "=== epoch:240, train acc:0.5166666666666667, test acc:0.4338 ===\n",
            "train loss:1.4304218924461163\n",
            "train loss:1.3976969657595877\n",
            "train loss:1.5007043316695536\n",
            "=== epoch:241, train acc:0.52, test acc:0.4335 ===\n",
            "train loss:1.5738379128979347\n",
            "train loss:1.44457418508521\n",
            "train loss:1.3795346424359918\n",
            "=== epoch:242, train acc:0.5166666666666667, test acc:0.4341 ===\n",
            "train loss:1.3598040319263456\n",
            "train loss:1.3921768231001272\n",
            "train loss:1.3519495578387304\n",
            "=== epoch:243, train acc:0.52, test acc:0.4331 ===\n",
            "train loss:1.5074222672897561\n",
            "train loss:1.4304388031683113\n",
            "train loss:1.5022429698776099\n",
            "=== epoch:244, train acc:0.52, test acc:0.4324 ===\n",
            "train loss:1.4736322785613465\n",
            "train loss:1.376828680256785\n",
            "train loss:1.5752994705296695\n",
            "=== epoch:245, train acc:0.52, test acc:0.4341 ===\n",
            "train loss:1.6632205299309302\n",
            "train loss:1.3790072987048325\n",
            "train loss:1.4713411486028791\n",
            "=== epoch:246, train acc:0.5166666666666667, test acc:0.4346 ===\n",
            "train loss:1.3710825909035433\n",
            "train loss:1.4505336945711251\n",
            "train loss:1.4401544914423972\n",
            "=== epoch:247, train acc:0.5166666666666667, test acc:0.4347 ===\n",
            "train loss:1.3606591739989655\n",
            "train loss:1.3754061758354985\n",
            "train loss:1.5338958475616449\n",
            "=== epoch:248, train acc:0.5166666666666667, test acc:0.434 ===\n",
            "train loss:1.5086303164533672\n",
            "train loss:1.4739032311170135\n",
            "train loss:1.3801581087917705\n",
            "=== epoch:249, train acc:0.5166666666666667, test acc:0.4338 ===\n",
            "train loss:1.4367967509240935\n",
            "train loss:1.343679840684075\n",
            "train loss:1.5662542981572292\n",
            "=== epoch:250, train acc:0.5166666666666667, test acc:0.4361 ===\n",
            "train loss:1.3589456131375346\n",
            "train loss:1.5317697352706794\n",
            "train loss:1.5912722858139574\n",
            "=== epoch:251, train acc:0.52, test acc:0.4374 ===\n",
            "train loss:1.3584392953766764\n",
            "train loss:1.493034366472716\n",
            "train loss:1.4672693338067675\n",
            "=== epoch:252, train acc:0.5166666666666667, test acc:0.4344 ===\n",
            "train loss:1.3778923307389177\n",
            "train loss:1.4544658534831876\n",
            "train loss:1.484260346890777\n",
            "=== epoch:253, train acc:0.52, test acc:0.4373 ===\n",
            "train loss:1.502271838168511\n",
            "train loss:1.470773328839011\n",
            "train loss:1.3480968575275651\n",
            "=== epoch:254, train acc:0.52, test acc:0.4379 ===\n",
            "train loss:1.378809354740614\n",
            "train loss:1.349933158199778\n",
            "train loss:1.509687871349521\n",
            "=== epoch:255, train acc:0.5166666666666667, test acc:0.4365 ===\n",
            "train loss:1.309798334695125\n",
            "train loss:1.3312492195255476\n",
            "train loss:1.4403859312435785\n",
            "=== epoch:256, train acc:0.5166666666666667, test acc:0.4387 ===\n",
            "train loss:1.3567468103089526\n",
            "train loss:1.3859081377876228\n",
            "train loss:1.2959282751008467\n",
            "=== epoch:257, train acc:0.5166666666666667, test acc:0.435 ===\n",
            "train loss:1.2878351617979475\n",
            "train loss:1.309049010895305\n",
            "train loss:1.4714822019032954\n",
            "=== epoch:258, train acc:0.52, test acc:0.4357 ===\n",
            "train loss:1.5511884506886957\n",
            "train loss:1.4622742684866066\n",
            "train loss:1.4195608281551073\n",
            "=== epoch:259, train acc:0.52, test acc:0.4358 ===\n",
            "train loss:1.4129789326340574\n",
            "train loss:1.2493098899521675\n",
            "train loss:1.4545761455496973\n",
            "=== epoch:260, train acc:0.5166666666666667, test acc:0.4352 ===\n",
            "train loss:1.3356590974411031\n",
            "train loss:1.5613751056652676\n",
            "train loss:1.4585343989460355\n",
            "=== epoch:261, train acc:0.52, test acc:0.438 ===\n",
            "train loss:1.4820224513668419\n",
            "train loss:1.3778719922336902\n",
            "train loss:1.2865862882673462\n",
            "=== epoch:262, train acc:0.52, test acc:0.437 ===\n",
            "train loss:1.4228356727947284\n",
            "train loss:1.3571048250932045\n",
            "train loss:1.4166812370026878\n",
            "=== epoch:263, train acc:0.52, test acc:0.4385 ===\n",
            "train loss:1.3662956165666693\n",
            "train loss:1.5177709855190489\n",
            "train loss:1.4534485689265537\n",
            "=== epoch:264, train acc:0.5166666666666667, test acc:0.4367 ===\n",
            "train loss:1.4441562909250618\n",
            "train loss:1.4381165986245075\n",
            "train loss:1.3824767455940516\n",
            "=== epoch:265, train acc:0.5133333333333333, test acc:0.4362 ===\n",
            "train loss:1.4445941292140085\n",
            "train loss:1.38483346531643\n",
            "train loss:1.3553466309329993\n",
            "=== epoch:266, train acc:0.52, test acc:0.4393 ===\n",
            "train loss:1.302567689864656\n",
            "train loss:1.3873481952232547\n",
            "train loss:1.3667414412958296\n",
            "=== epoch:267, train acc:0.5233333333333333, test acc:0.4423 ===\n",
            "train loss:1.2864502674522424\n",
            "train loss:1.349974425025524\n",
            "train loss:1.4945660498552271\n",
            "=== epoch:268, train acc:0.5266666666666666, test acc:0.4437 ===\n",
            "train loss:1.4346904775633866\n",
            "train loss:1.4635954112290983\n",
            "train loss:1.3614580610631861\n",
            "=== epoch:269, train acc:0.5266666666666666, test acc:0.4449 ===\n",
            "train loss:1.3580838266023716\n",
            "train loss:1.4384847348297418\n",
            "train loss:1.252295744414437\n",
            "=== epoch:270, train acc:0.5266666666666666, test acc:0.4436 ===\n",
            "train loss:1.3235341191258385\n",
            "train loss:1.5004251253326784\n",
            "train loss:1.2754384618251695\n",
            "=== epoch:271, train acc:0.53, test acc:0.447 ===\n",
            "train loss:1.5988217273080412\n",
            "train loss:1.3634025396542315\n",
            "train loss:1.2835158731663163\n",
            "=== epoch:272, train acc:0.5233333333333333, test acc:0.4467 ===\n",
            "train loss:1.247082585507306\n",
            "train loss:1.355244690399397\n",
            "train loss:1.4903943883242678\n",
            "=== epoch:273, train acc:0.5266666666666666, test acc:0.4459 ===\n",
            "train loss:1.386330717849012\n",
            "train loss:1.3849437112009735\n",
            "train loss:1.3141723669710617\n",
            "=== epoch:274, train acc:0.5233333333333333, test acc:0.4454 ===\n",
            "train loss:1.2365166995569512\n",
            "train loss:1.3358048128358482\n",
            "train loss:1.3116497925215669\n",
            "=== epoch:275, train acc:0.5233333333333333, test acc:0.4453 ===\n",
            "train loss:1.3121664335742858\n",
            "train loss:1.4437630217144575\n",
            "train loss:1.268030791422213\n",
            "=== epoch:276, train acc:0.5233333333333333, test acc:0.4455 ===\n",
            "train loss:1.2069529108533403\n",
            "train loss:1.2330700307446236\n",
            "train loss:1.2666460074990935\n",
            "=== epoch:277, train acc:0.5266666666666666, test acc:0.4444 ===\n",
            "train loss:1.3724452545449237\n",
            "train loss:1.2996569554453208\n",
            "train loss:1.2988963397894937\n",
            "=== epoch:278, train acc:0.5266666666666666, test acc:0.4447 ===\n",
            "train loss:1.3112347238659507\n",
            "train loss:1.2131542904836023\n",
            "train loss:1.5548456636447798\n",
            "=== epoch:279, train acc:0.5266666666666666, test acc:0.4458 ===\n",
            "train loss:1.213196118178551\n",
            "train loss:1.350322269032917\n",
            "train loss:1.332927185636645\n",
            "=== epoch:280, train acc:0.5233333333333333, test acc:0.4455 ===\n",
            "train loss:1.2670111231234948\n",
            "train loss:1.275972522184098\n",
            "train loss:1.4348816149421537\n",
            "=== epoch:281, train acc:0.5233333333333333, test acc:0.4447 ===\n",
            "train loss:1.1136448021168812\n",
            "train loss:1.2560062586219363\n",
            "train loss:1.0739046616120462\n",
            "=== epoch:282, train acc:0.5266666666666666, test acc:0.4422 ===\n",
            "train loss:1.4132599426016563\n",
            "train loss:1.0971702680860298\n",
            "train loss:1.242632990634476\n",
            "=== epoch:283, train acc:0.5266666666666666, test acc:0.4402 ===\n",
            "train loss:1.2899669200489927\n",
            "train loss:1.272621414884712\n",
            "train loss:1.2953474050635767\n",
            "=== epoch:284, train acc:0.5266666666666666, test acc:0.439 ===\n",
            "train loss:1.3032352155664402\n",
            "train loss:1.3172907193529482\n",
            "train loss:1.2053944575308364\n",
            "=== epoch:285, train acc:0.53, test acc:0.441 ===\n",
            "train loss:1.2338168960105715\n",
            "train loss:1.1765576230768977\n",
            "train loss:1.299635135788763\n",
            "=== epoch:286, train acc:0.53, test acc:0.4421 ===\n",
            "train loss:1.3130653443707105\n",
            "train loss:1.289690964248557\n",
            "train loss:1.3101161733569733\n",
            "=== epoch:287, train acc:0.53, test acc:0.4417 ===\n",
            "train loss:1.0743810828472835\n",
            "train loss:1.216617554908959\n",
            "train loss:1.262439482505129\n",
            "=== epoch:288, train acc:0.5266666666666666, test acc:0.4403 ===\n",
            "train loss:1.2641079294239064\n",
            "train loss:1.336756251151916\n",
            "train loss:1.3366314240033628\n",
            "=== epoch:289, train acc:0.5266666666666666, test acc:0.443 ===\n",
            "train loss:1.128445409110949\n",
            "train loss:1.2161145167685303\n",
            "train loss:1.3051727872057186\n",
            "=== epoch:290, train acc:0.5166666666666667, test acc:0.4432 ===\n",
            "train loss:1.4198487600471799\n",
            "train loss:1.1794014468164087\n",
            "train loss:1.2290400453219492\n",
            "=== epoch:291, train acc:0.5166666666666667, test acc:0.4437 ===\n",
            "train loss:1.2694476188358979\n",
            "train loss:1.2482641875542404\n",
            "train loss:1.1751895238369814\n",
            "=== epoch:292, train acc:0.53, test acc:0.4483 ===\n",
            "train loss:1.222939045283136\n",
            "train loss:1.4718955409232268\n",
            "train loss:1.174793061939524\n",
            "=== epoch:293, train acc:0.5333333333333333, test acc:0.4518 ===\n",
            "train loss:1.3801116517582954\n",
            "train loss:1.316281049246325\n",
            "train loss:1.4291709754181263\n",
            "=== epoch:294, train acc:0.5366666666666666, test acc:0.4536 ===\n",
            "train loss:1.13696156569733\n",
            "train loss:1.2055024554686873\n",
            "train loss:1.3561396835517388\n",
            "=== epoch:295, train acc:0.54, test acc:0.4553 ===\n",
            "train loss:1.3735214975822643\n",
            "train loss:1.3171692791740726\n",
            "train loss:1.2876362846922842\n",
            "=== epoch:296, train acc:0.5433333333333333, test acc:0.4569 ===\n",
            "train loss:1.2539927146143028\n",
            "train loss:1.3838090575629298\n",
            "train loss:1.1661267135486306\n",
            "=== epoch:297, train acc:0.5433333333333333, test acc:0.457 ===\n",
            "train loss:1.0532528192894925\n",
            "train loss:1.2882027863246264\n",
            "train loss:1.2121047436784134\n",
            "=== epoch:298, train acc:0.5466666666666666, test acc:0.455 ===\n",
            "train loss:1.218077173721233\n",
            "train loss:1.2514131965442639\n",
            "train loss:1.1948285355729944\n",
            "=== epoch:299, train acc:0.5533333333333333, test acc:0.4572 ===\n",
            "train loss:1.1274973029611575\n",
            "train loss:1.285499611688425\n",
            "train loss:1.2034898516238675\n",
            "=== epoch:300, train acc:0.5566666666666666, test acc:0.4583 ===\n",
            "train loss:1.2880350473147473\n",
            "train loss:1.158256089555995\n",
            "train loss:1.2149349435251948\n",
            "=== epoch:301, train acc:0.56, test acc:0.4571 ===\n",
            "train loss:1.2300334099311554\n",
            "train loss:1.254143755890007\n",
            "=============== Final Test Accuracy ===============\n",
            "test acc:0.4587\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
        "from common.trainer import Trainer\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임(300개로)\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "# 드롭아웃 사용 유무와 비율 설정=====\n",
        "use_dropout = True # drop out 쓰지 않을 때는 False\n",
        "dropput_ratio = 0.2 # drop out 비율\n",
        "# =================================\n",
        "\n",
        "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                        output_size=10, use_dropout=use_dropout, dropout_ration=dropput_ratio)\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                epochs=301, mini_batch_size=100,\n",
        "                optimizer='sgd', optimizer_param={'lr':0.01}, verbose=True)\n",
        "trainer.train()\n",
        "\n",
        "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
        "\n",
        "markers = {\"train\": \"o\", \"test\": \"s\"}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
